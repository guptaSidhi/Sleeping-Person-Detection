{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e610528b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 495ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "tf.Tensor([[31.075558]], shape=(1, 1), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EC75055090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EC75055090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "tf.Tensor([[30.652832]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[29.534634]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[29.495617]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9 (update_frame):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sidhi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Sidhi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Sidhi\\AppData\\Local\\Temp\\ipykernel_7284\\4200493759.py\", line 246, in update_frame\n",
      "  File \"C:\\Users\\Sidhi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py\", line 1675, in configure\n",
      "    return self._configure('configure', cnf, kw)\n",
      "  File \"C:\\Users\\Sidhi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py\", line 1665, in _configure\n",
      "    self.tk.call(_flatten((self._w, cmd)) + self._options(cnf))\n",
      "_tkinter.TclError: invalid command name \".!toplevel.!label\"\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, Toplevel\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Classifier class to handle model loading and predictions\n",
    "class Classifier:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = tf.saved_model.load(model_path)\n",
    "        self.predict_fn = self.create_predict_function()\n",
    "\n",
    "    def create_predict_function(self):\n",
    "        @tf.function\n",
    "        def predict_function(features):\n",
    "            return self.model.signatures['serving_default'](input_1=features)\n",
    "        return predict_function\n",
    "\n",
    "    def predict(self, features):\n",
    "        return self.predict_fn(features)\n",
    "\n",
    "class AgeClassifier:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = tf.saved_model.load(model_path)\n",
    "        self.predict_fn = self.model.signatures['serving_default']\n",
    "\n",
    "    def predict(self, features):\n",
    "        output = self.predict_fn(keras_tensor_13=features)\n",
    "        predicted_age = output['output_0']\n",
    "        print(predicted_age)\n",
    "        return predicted_age\n",
    "\n",
    "# Function to detect vehicles\n",
    "def detect_vehicle(image, classifier):\n",
    "    img_resized = cv2.resize(image, (416, 416))\n",
    "    img_array = np.expand_dims(img_resized, axis=0).astype(np.float32) / 255.0\n",
    "    predictions = classifier.predict(img_array)\n",
    "    vehicle_labels = {0: 'Ambulance', 1: 'Bus', 2: 'Car', 3: 'Motorcycle', 4: 'Truck'}\n",
    "    class_index = np.argmax(predictions)\n",
    "    return vehicle_labels[class_index] == 'Car'\n",
    "\n",
    "# Function to detect faces using MTCNN\n",
    "def detect_faces(image):\n",
    "    detector = MTCNN()\n",
    "    faces = detector.detect_faces(image)\n",
    "    bounding_boxes = [face['box'] for face in faces]\n",
    "    return bounding_boxes, len(faces)\n",
    "\n",
    "# Function to predict sleeping\n",
    "def predict_sleeping(face, classifier):\n",
    "    face_resized = cv2.resize(face, (224, 224))\n",
    "    face_array = np.expand_dims(face_resized, axis=0).astype(np.float32) / 255.0\n",
    "    predictions = classifier.predict(face_array)\n",
    "    sleeping_labels = {0: 'Drowsy', 1: 'Awake'}\n",
    "    class_index = np.argmax(predictions)\n",
    "    return sleeping_labels[class_index] == 'Drowsy'\n",
    "\n",
    "# Function to predict age\n",
    "def predict_age(face, classifier):\n",
    "    face_resized = cv2.resize(face, (128, 128))\n",
    "    face_array = np.expand_dims(face_resized, axis=0).astype(np.float32) / 255.0\n",
    "    face_array = face_array[:, :, :, 0:1]  # Extract the first channel and keep the shape (1, 128, 128, 1)\n",
    "    predicted_age = classifier.predict(face_array)[0][0]\n",
    "    return predicted_age\n",
    "\n",
    "# Function to process image or video\n",
    "def process_media(input_path, vehicle_classifier, sleeping_classifier, age_classifier, video_label=None, is_video=False):\n",
    "    if is_video:\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter('processed_video.mp4', fourcc, 30, (640, 480))\n",
    "        \n",
    "        num_sleeping = 0\n",
    "        \n",
    "        def process_frames():\n",
    "            nonlocal num_sleeping\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                frame = cv2.resize(frame, (640, 480))\n",
    "                \n",
    "                # Detect vehicle\n",
    "                if not detect_vehicle(frame, vehicle_classifier):\n",
    "                    continue\n",
    "                \n",
    "                # Detect faces using MTCNN\n",
    "                faces, num_faces = detect_faces(frame)\n",
    "                print(f\"Number of faces detected: {num_faces}\")\n",
    "                \n",
    "                # Count the number of sleeping persons\n",
    "                for (x, y, w, h) in faces:\n",
    "                    face = frame[y:y+h, x:x+w]\n",
    "                    # Predict sleeping\n",
    "                    if predict_sleeping(face, sleeping_classifier):\n",
    "                        num_sleeping += 1\n",
    "                        # Predict age\n",
    "                        age = int(predict_age(face, age_classifier))\n",
    "                        label = f\"Age:{age}\"\n",
    "                        # Draw rectangle around the face\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                        # Display label\n",
    "                        cv2.putText(frame, label, (x, y - 15), cv2.FONT_HERSHEY_TRIPLEX, 0.7, (0, 0, 255), 1)\n",
    "\n",
    "                # Convert frame to PhotoImage\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_pil = Image.fromarray(frame_rgb)\n",
    "                frame_tk = ImageTk.PhotoImage(image=frame_pil)\n",
    "                video_label.configure(image=frame_tk)\n",
    "                video_label.image = frame_tk\n",
    "                \n",
    "                # Write the processed frame to the video file\n",
    "                out.write(frame)\n",
    "                \n",
    "                time.sleep(0.033) \n",
    "        \n",
    "        video_thread = threading.Thread(target=process_frames)\n",
    "        video_thread.start()\n",
    "\n",
    "        while video_thread.is_alive():\n",
    "            video_thread.join(0.1)\n",
    "        \n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        return 'processed_video.mp4', num_sleeping\n",
    "    else:\n",
    "        frame = cv2.imread(input_path)\n",
    "        \n",
    "        # Detect vehicle\n",
    "        if not detect_vehicle(frame, vehicle_classifier):\n",
    "            messagebox.showinfo(\"Info\", \"No car detected in the image. Processing stopped.\")\n",
    "            return None, 0\n",
    "        \n",
    "        faces, num_faces = detect_faces(frame)\n",
    "        \n",
    "        num_sleeping = 0\n",
    "        for (x, y, w, h) in faces:\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            # Predict sleeping\n",
    "            if predict_sleeping(face, sleeping_classifier):\n",
    "                num_sleeping += 1\n",
    "                # Predict age\n",
    "                age = int(predict_age(face, age_classifier))\n",
    "                label = f\"Age:{age}\"\n",
    "                # Draw rectangle around the face\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                # Display label\n",
    "                cv2.putText(frame, label, (x, y - 15), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (0, 0, 255), 1)\n",
    "        \n",
    "        # Save the processed image\n",
    "        cv2.imwrite('processed_image.jpg', frame)\n",
    "        \n",
    "        return 'processed_image.jpg', num_sleeping\n",
    "\n",
    "# Tkinter GUI\n",
    "class App:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Sleep Detection\")\n",
    "        \n",
    "        self.label = tk.Label(root, text=\"Upload an image or video:\")\n",
    "        self.label.pack(pady=20)\n",
    "        \n",
    "        self.image_button = tk.Button(root, text=\"Upload Image\", command=self.upload_image)\n",
    "        self.image_button.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        self.video_button = tk.Button(root, text=\"Upload Video\", command=self.upload_video)\n",
    "        self.video_button.pack(side=tk.RIGHT, padx=10)\n",
    "        \n",
    "        self.image_label = tk.Label(root)\n",
    "        self.image_label.pack(pady=20)\n",
    "        \n",
    "        self.sleeping_persons_label = tk.Label(root, font=(\"Arial\", 12))\n",
    "        self.sleeping_persons_label.pack(pady=10)\n",
    "\n",
    "        # Load models using Classifier class\n",
    "        self.vehicle_classifier = Classifier('Vehicle Classification Model')\n",
    "        self.sleeping_classifier = Classifier('Sleeping_Detection_Model')\n",
    "        self.age_classifier = AgeClassifier('Age Prediction Model')\n",
    "\n",
    "    def upload_image(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "        if file_path:\n",
    "            self.process_image(file_path)\n",
    "\n",
    "    def upload_video(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Video Files\", \"*.mp4;*.avi;*.mov\")])\n",
    "        if file_path:\n",
    "            self.process_video(file_path)\n",
    "\n",
    "    def process_image(self, file_path):\n",
    "        messagebox.showinfo(\"Info\", f\"Processing image: {file_path}. Please wait.\")\n",
    "        processed_frame, num_sleeping = process_media(file_path, self.vehicle_classifier, self.sleeping_classifier, self.age_classifier, is_video=False)\n",
    "        if processed_frame:\n",
    "            self.display_image(processed_frame, num_sleeping)\n",
    "        else:\n",
    "            self.image_label.configure(image='')\n",
    "            self.image_label.image = None\n",
    "            self.sleeping_persons_label.configure(text=\"No car detected.\")\n",
    "\n",
    "    def process_video(self, file_path):\n",
    "        messagebox.showinfo(\"Info\", f\"Processing video: {file_path}. Please wait.\")\n",
    "        video_window = Toplevel(self.root)\n",
    "        video_window.title(\"Video Output\")\n",
    "        video_label = tk.Label(video_window)\n",
    "        video_label.pack()\n",
    "\n",
    "        def update_frame():\n",
    "            cap = cv2.VideoCapture(file_path)\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Detect vehicle\n",
    "                if detect_vehicle(frame, self.vehicle_classifier):\n",
    "                    # Detect faces using MTCNN\n",
    "                    faces, num_faces = detect_faces(frame)\n",
    "                    print(f\"Number of faces detected: {num_faces}\")\n",
    "                    \n",
    "                    # Count the number of sleeping persons\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face = frame[y:y+h, x:x+w]\n",
    "                        # Predict sleeping\n",
    "                        if predict_sleeping(face, self.sleeping_classifier):\n",
    "                            # Predict age\n",
    "                            age = int(predict_age(face, self.age_classifier))\n",
    "                            label = f\"Age:{age}\"\n",
    "                            # Draw rectangle around the face\n",
    "                            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                            # Display label\n",
    "                            cv2.putText(frame, label, (x, y - 15), cv2.FONT_HERSHEY_TRIPLEX, 0.7, (0, 0, 255), 1)\n",
    "                \n",
    "                # Convert frame to PhotoImage\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_pil = Image.fromarray(frame_rgb)\n",
    "                frame_tk = ImageTk.PhotoImage(image=frame_pil)\n",
    "                video_label.configure(image=frame_tk)\n",
    "                video_label.image = frame_tk\n",
    "\n",
    "        threading.Thread(target=update_frame).start()\n",
    "\n",
    "    def display_image(self, file_path, num_sleeping):\n",
    "        image_pil = Image.open(file_path)\n",
    "        image_tk = ImageTk.PhotoImage(image=image_pil)\n",
    "        \n",
    "        self.image_label.configure(image=image_tk)\n",
    "        self.image_label.image = image_tk\n",
    "        \n",
    "        self.sleeping_persons_label.configure(text=f\"Number of sleeping persons: {num_sleeping}\")\n",
    "\n",
    "# Create the main Tkinter window\n",
    "root = tk.Tk()\n",
    "app = App(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de843e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e885d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
